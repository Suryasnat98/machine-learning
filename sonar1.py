# -*- coding: utf-8 -*-
"""sonar1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TjUUpwpk8uLG7Dsh5afsAhCclapQKqOp
"""

#importing the dependencies
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

sonar_data = pd.read_csv('/content/sonar1.csv',header=None)

print(sonar_data.head())

sonar_data.shape

#dividing the dataset into features and target
X = sonar_data.drop(columns=60,axis=1)
Y = sonar_data[60]

print(X)

print(Y)

#dividing the dataset into training and test data
X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=2)

"""model training --> logistic regression"""

model = LogisticRegression()
model.fit(X_train,Y_train)

"""Model Evaluation

This is the most important step

after you have trained the model(in this case LogisticRegression) , you have to make predictions on new unseen data using a trained model. so we use model.predict() on new input features like x_test or X_train to get model's output,i.e., R or M
"""

#accuracy on training data
X_train_prediction = model.predict(X_train)
train_data_accuracy = accuracy_score(X_train_prediction,Y_train)

print(train_data_accuracy)

#accuracy on test data
X_test_prediction = model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction,Y_test)

print(test_data_accuracy)

"""Building a predictive system"""

input_data = (0.0200,0.0371,0.0428,0.0207,0.0954,0.0986,0.1539,0.1601,0.3109,0.2111,0.1609,0.1582,0.2238,0.0645,0.0660,0.2273,0.3100,0.2999,0.5078,0.4797,0.5783,0.5071,0.4328,0.5550,0.6711,0.6415,0.7104,0.8080,0.6791,0.3857,0.1307,0.2604,0.5121,0.7547,0.8537,0.8507,0.6692,0.6097,0.4943,0.2744,0.0510,0.2834,0.2825,0.4256,0.2641,0.1386,0.1051,0.1343,0.0383,0.0324,0.0232,0.0027,0.0065,0.0159,0.0072,0.0167,0.0180,0.0084,0.0090,0.0032)

#changing the input data to a numpy array
input_data_array = np.asarray(input_data)

"""1: This specifies that the reshaped array should have 1 row. In machine learning, when you're making a prediction for a single data point, models typically expect the input to be in the form of a 2D array, even if it's just one row of features.


-1: This is a placeholder. NumPy automatically calculates the appropriate number of columns (or the size of the dimension) needed to accommodate all the elements from the original array. Since you have 60 features in your input_data, -1 will be interpreted as 60, resulting in a 2D array with 1 row and 60 columns.
"""

#reshape the np array as we are predicting for one instance
input_data_reshaped = input_data_array.reshape(1,-1)

prediction = model.predict(input_data_reshaped)

print(prediction)

if(prediction[0]=='R'):
  print('The object is a Rock')
else:
  print('The object is a mine')

